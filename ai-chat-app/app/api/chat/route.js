/**
 * ============================================================================
 * AI èŠå¤© API (app/api/chat/route.js)
 * ============================================================================
 *
 * æ–‡ä»¶ä½œç”¨ï¼š
 *   å¤„ç† AI èŠå¤©è¯·æ±‚ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡è¾“å…¥å’Œè”ç½‘æœç´¢ï¼Œè¿”å›æµå¼å“åº”
 *
 * ä¸»è¦åŠŸèƒ½ï¼š
 *   1. æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯å’Œå›¾ç‰‡
 *   2. å°†æœ¬åœ°å›¾ç‰‡è½¬æ¢ä¸º Base64 æ ¼å¼
 *   3. è°ƒç”¨ LLM Serviceï¼ˆæ”¯æŒæ™®é€šå¯¹è¯å’Œè”ç½‘æœç´¢ï¼‰âœ¨ ä¿®æ”¹
 *   4. è¿”å›æµå¼å“åº”ï¼ˆServer-Sent Eventsï¼‰
 *
 * è·¯ç”±ï¼šPOST /api/chat
 *
 * è¯·æ±‚ä½“ï¼š
 *   {
 *     messages: Array<{role, content}>,  // èŠå¤©å†å²
 *     model: string,                     // æ¨¡å‹åç§°
 *     images?: Array<string>,            // å›¾ç‰‡ URL åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
 *     useWebSearch?: boolean             // ğŸ†• æ˜¯å¦ä½¿ç”¨è”ç½‘æœç´¢ï¼ˆå¯é€‰ï¼‰
 *   }
 *
 * å“åº”ï¼š
 *   - Content-Type: text/event-streamï¼ˆæµå¼å“åº”ï¼‰
 *   - æ ¼å¼ï¼šdata: {"content": "..."}\n\n
 *
 * æŠ€æœ¯æ ˆï¼š
 *   - LLM Serviceï¼ˆç‹¬ç«‹ AI æœåŠ¡ï¼‰
 *   - OpenAI APIï¼ˆé€šè¿‡ LLM Serviceï¼‰
 *   - Server-Sent Eventsï¼ˆæµå¼ä¼ è¾“ï¼‰
 *
 * ============================================================================
 */

import { promises as fs } from 'fs';
import path from 'path';
import log from '@/lib/log';

// ============================================================================
// LLM Service é…ç½®
// ============================================================================
const LLM_SERVICE_URL = process.env.LLM_SERVICE_URL || 'http://llm-service:8002';

/**
 * POST - AI èŠå¤©æ¥å£
 *
 * æµç¨‹ï¼š
 *   1. éªŒè¯è¯·æ±‚å‚æ•°
 *   2. åˆ¤æ–­ä½¿ç”¨æ™®é€šå¯¹è¯è¿˜æ˜¯è”ç½‘æœç´¢ ğŸ†•
 *   3. å¤„ç†å›¾ç‰‡ï¼ˆè½¬ Base64ï¼‰
 *   4. æ„é€ å¤šæ¨¡æ€æ¶ˆæ¯
 *   5. è°ƒç”¨ LLM Service
 *   6. è¿”å›æµå¼å“åº”
 */
export async function POST(req) {
  try {
    // ========================================================================
    // 1. è§£æè¯·æ±‚ä½“
    // ========================================================================
    // ğŸ†• ä¿®æ”¹ï¼šæ·»åŠ  useWebSearch å‚æ•°
    const { messages, model, images, useWebSearch = false } = await req.json();

    // éªŒè¯å¿…å¡«å‚æ•°
    if (!messages || !model) {
      return new Response(
        JSON.stringify({
          error: 'Invalid input: messages or model is missing',
        }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      );
    }

    // ========================================================================
    // ğŸ†• 2. åˆ¤æ–­ä½¿ç”¨å“ªç§æ¨¡å¼
    // ========================================================================
    const lastMessage = messages[messages.length - 1];
    const userQuery = lastMessage.content;

    // å¦‚æœå¯ç”¨è”ç½‘æœç´¢ä¸”æ²¡æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨æœç´¢æ¥å£
    if (useWebSearch && (!images || images.length === 0)) {
      log.debug('ğŸ” ä½¿ç”¨è”ç½‘æœç´¢æ¨¡å¼');
      return handleWebSearch(messages, model, userQuery);
    }

    // å¦åˆ™ä½¿ç”¨æ™®é€šç”Ÿæˆæ¥å£ï¼ˆæ”¯æŒå›¾ç‰‡ï¼‰
    log.debug('ğŸ’¬ ä½¿ç”¨æ™®é€šå¯¹è¯æ¨¡å¼');
    return handleNormalChat(messages, model, images);
    
  } catch (error) {
    console.error('âŒ Error in /api/chat route:', error);

    return new Response(
      JSON.stringify({
        error: 'Internal Server Error',
        details: error.message,
      }),
      { status: 500, headers: { 'Content-Type': 'application/json' } }
    );
  }
}

// ============================================================================
// ğŸ†• æ–°å¢å‡½æ•°ï¼šå¤„ç†æ™®é€šå¯¹è¯ï¼ˆæ”¯æŒå›¾ç‰‡ï¼‰
// ============================================================================
/**
 * å¤„ç†æ™®é€šå¯¹è¯ï¼ˆæ”¯æŒå›¾ç‰‡ï¼‰
 * 
 * è¿™æ˜¯å°†åŸæ¥ POST å‡½æ•°ä¸­çš„ä¸»è¦é€»è¾‘æå–å‡ºæ¥çš„å‡½æ•°
 */
async function handleNormalChat(messages, model, images) {
  try {
    // ========================================================================
    // 1. å¤„ç†å›¾ç‰‡è¾“å…¥ï¼ˆè½¬æ¢ä¸º Base64ï¼‰
    // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
    // ========================================================================
    const lastMessage = messages[messages.length - 1];
    let processedMessages = [...messages.slice(0, -1)];

    if (images && images.length > 0) {
      try {
        const base64Images = await Promise.all(
          images.map(async (imageUrl) => {
            try {
              if (
                imageUrl.startsWith('http:') ||
                imageUrl.startsWith('/') ||
                imageUrl.startsWith('https:')
              ) {
                let filePath;
                let urlPath;

                if (
                  imageUrl.startsWith('http:') ||
                  imageUrl.startsWith('https:')
                ) {
                  urlPath = new URL(imageUrl).pathname;
                } else {
                  urlPath = imageUrl;
                }

                if (urlPath.includes('/api/files/')) {
                  const actualPath = urlPath.split('/api/files/')[1];
                  filePath = path.join(process.cwd(), 'public', actualPath);
                } else {
                  filePath = path.join(process.cwd(), 'public', urlPath);
                }

                log.debug('ğŸ” åŸå§‹ URL:', imageUrl);
                log.debug('ğŸ” æå–è·¯å¾„:', urlPath);
                log.debug('ğŸ–¼ï¸ æ–‡ä»¶è·¯å¾„:', filePath);

                try {
                  await fs.access(filePath);
                } catch {
                  throw new Error(`File not found: ${filePath}`);
                }

                const imageBuffer = await fs.readFile(filePath);
                const base64Image = imageBuffer.toString('base64');

                const ext = path.extname(filePath).toLowerCase();
                let mimeType = 'image/jpeg';
                if (ext === '.png') mimeType = 'image/png';
                else if (ext === '.gif') mimeType = 'image/gif';
                else if (ext === '.webp') mimeType = 'image/webp';

                return `data:${mimeType};base64,${base64Image}`;
              } else {
                return imageUrl;
              }
            } catch (error) {
              console.error(`Error processing image ${imageUrl}:`, error);
              throw error;
            }
          })
        );

        const multimodalMessage = {
          role: 'user',
          content: [
            {
              type: 'text',
              text: lastMessage.content || 'è¯·åˆ†æè¿™å¼ å›¾ç‰‡',
            },
            ...base64Images.map((base64Image) => ({
              type: 'image_url',
              image_url: {
                url: base64Image,
              },
            })),
          ],
        };

        processedMessages.push(multimodalMessage);
      } catch (imageError) {
        console.error('Error processing images:', imageError);

        const fallbackMessage = {
          role: 'user',
          content: `${lastMessage.content} [å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œä½†ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡]`,
        };
        processedMessages.push(fallbackMessage);
      }
    } else {
      processedMessages.push(lastMessage);
    }

    // ========================================================================
    // 2. æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆå®šä¹‰ AI è¡Œä¸ºï¼‰
    // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
    // ========================================================================
    const systemMessage = {
      role: 'system',
      content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å¥½ã€åšå­¦çš„ AI åŠ©æ‰‹ï¼Œåå­—å¯ä»¥å«"æ™ºèƒ½åŠ©æ‰‹"ã€‚
                ## æ ¸å¿ƒèƒ½åŠ›
                - ğŸ’¬ è‡ªç„¶å¯¹è¯ï¼šç†è§£ä¸Šä¸‹æ–‡ï¼Œæä¾›è¿è´¯çš„å¤šè½®å¯¹è¯
                - ğŸ§  çŸ¥è¯†å¹¿åšï¼šæ¶µç›–æŠ€æœ¯ã€ç§‘å­¦ã€äººæ–‡ã€ç”Ÿæ´»ç­‰å¤šä¸ªé¢†åŸŸ
                - ğŸ¨ åˆ›æ„æ€ç»´ï¼šå¸®åŠ©ç”¨æˆ·å¤´è„‘é£æš´ã€åˆ›ä½œå†…å®¹
                - ğŸ“Š æ•°æ®åˆ†æï¼šè§£è¯»æ•°æ®ã€æä¾›æ´å¯Ÿ
                - ğŸ–¼ï¸ å›¾åƒç†è§£ï¼šåˆ†æå’Œæè¿°å›¾ç‰‡å†…å®¹

                ## å›ç­”åŸåˆ™
                1. **ç»“æ„æ¸…æ™°**ï¼šä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ç­‰ Markdown æ ¼å¼
                2. **è¯¦ç»†å…¨é¢**ï¼šæä¾›å®Œæ•´çš„èƒŒæ™¯ã€æ­¥éª¤ã€ç¤ºä¾‹
                3. **å®ç”¨å¯è¡Œ**ï¼šç»™å‡ºå…·ä½“å¯æ“ä½œçš„å»ºè®®
                4. **å¼•ç”¨æ¥æº**ï¼šé‡è¦ä¿¡æ¯æ ‡æ³¨æ¥æºæˆ–ä¾æ®
                5. **å‹å¥½äº²å’Œ**ï¼šä½¿ç”¨é€‚å½“çš„è¡¨æƒ…ç¬¦å·ï¼Œè¯­æ°”æ¸©å’Œ

                ## ç‰¹æ®Šåœºæ™¯å¤„ç†
                - **æŠ€æœ¯é—®é¢˜**ï¼šæä¾›ä»£ç ç¤ºä¾‹ã€æœ€ä½³å®è·µã€å¸¸è§é™·é˜±
                - **å­¦ä¹ é—®é¢˜**ï¼šç»™å‡ºå­¦ä¹ è·¯å¾„ã€èµ„æºæ¨èã€æ—¶é—´è§„åˆ’
                - **åˆ›ä½œéœ€æ±‚**ï¼šæ¿€å‘çµæ„Ÿã€æä¾›å¤šä¸ªæ–¹æ¡ˆ
                - **é—®é¢˜è¯Šæ–­**ï¼šé€æ­¥åˆ†æã€å®šä½æ ¹å› ã€ç»™å‡ºè§£å†³æ–¹æ¡ˆ

                ## å›ç­”æ ¼å¼
                - ä½¿ç”¨ Markdown è¯­æ³•ç¾åŒ–æ’ç‰ˆ
                - ä»£ç ç”¨ \`\`\` ä»£ç å—åŒ…è£¹å¹¶æ ‡æ³¨è¯­è¨€
                - é‡è¦å†…å®¹ç”¨ **åŠ ç²—** æˆ– > å¼•ç”¨å—å¼ºè°ƒ
                - é€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ å¯è¯»æ€§ï¼ˆä½†ä¸è¿‡åº¦ï¼‰

                ## é™åˆ¶ä¸è¾¹ç•Œ
                - ä¸æä¾›åŒ»ç–—è¯Šæ–­ã€æ³•å¾‹å’¨è¯¢ç­‰ä¸“ä¸šå»ºè®®
                - ä¸ç”Ÿæˆæœ‰å®³ã€è¿æ³•ã€æ­§è§†æ€§å†…å®¹
                - é‡åˆ°ä¸ç¡®å®šçš„ä¿¡æ¯ä¼šæ˜ç¡®è¯´æ˜
                - ä¸å‡è£…èƒ½è®¿é—®å®æ—¶ä¿¡æ¯æˆ–å¤–éƒ¨ç³»ç»Ÿ
                ## å¤„ç†æ–‡æœ¬å’Œå›¾ç‰‡
                - ä½ å¯ä»¥å¤„ç†æ–‡æœ¬å’Œå›¾ç‰‡å†…å®¹ã€‚å½“ç”¨æˆ·æä¾›å›¾ç‰‡æ—¶ï¼Œè¯·è¯¦ç»†æè¿°å’Œåˆ†æå›¾ç‰‡å†…å®¹ã€‚`,
    };

    const finalMessages = [systemMessage, ...processedMessages];

    // ========================================================================
    // 3. è°ƒç”¨ LLM Service
    // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
    // ğŸ†• ä¿®æ”¹ï¼šæ·»åŠ è¶…æ—¶å¤„ç†
    // ========================================================================
    log.debug('ğŸ“¡ è°ƒç”¨ LLM Service:', LLM_SERVICE_URL);
    log.debug('ğŸ“ æ¶ˆæ¯æ•°é‡:', finalMessages.length);
    log.debug('ğŸ¤– æ¨¡å‹:', model);

    const llmResponse = await fetch(
      `${LLM_SERVICE_URL}/api/v1/generate/stream`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: finalMessages,
          model: model,
          max_tokens: 4000,
          temperature: 0.7,
          stream: true,
        }),
        // ğŸ†• ä¿®æ”¹ï¼šæ·»åŠ è¶…æ—¶ï¼ˆ60ç§’ï¼‰
        signal: AbortSignal.timeout(60000),
      }
    );

    if (!llmResponse.ok) {
      const errorText = await llmResponse.text();
      console.error('âŒ LLM Service é”™è¯¯:', errorText);

      return new Response(
        JSON.stringify({
          error: 'LLM Service é”™è¯¯',
          details: errorText,
        }),
        {
          status: llmResponse.status,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }

    log.debug('âœ… LLM Service å“åº”æˆåŠŸ');

    // ========================================================================
    // 4. è¿”å›æµå¼å“åº”
    // ğŸ†• ä¿®æ”¹ï¼šè°ƒç”¨ç»Ÿä¸€çš„æµå¤„ç†å‡½æ•°
    // ========================================================================
    return createStreamResponse(llmResponse, false);
    
  } catch (error) {
    console.error('âŒ Normal chat error:', error);
    return new Response(
      JSON.stringify({ error: error.message || 'Internal server error' }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
}

// ============================================================================
// ğŸ†• æ–°å¢å‡½æ•°ï¼šå¤„ç†è”ç½‘æœç´¢
// ============================================================================
/**
 * å¤„ç†è”ç½‘æœç´¢
 * 
 * @param {Array} messages - èŠå¤©å†å²
 * @param {string} model - æ¨¡å‹åç§°
 * @param {string} userQuery - ç”¨æˆ·æŸ¥è¯¢
 */
async function handleWebSearch(messages, model, userQuery) {
  try {
    log.debug('ğŸ” å¼€å§‹è”ç½‘æœç´¢:', userQuery);

    // ========================================================================
    // 1. æ„å»ºèŠå¤©å†å²ï¼ˆæ’é™¤æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
    // ========================================================================
    const chatHistory = messages.slice(0, -1).map((msg) => ({
      role: msg.role,
      content: msg.content,
    }));

    // ========================================================================
    // 2. è°ƒç”¨ LLM Service æœç´¢æ¥å£
    // ========================================================================
    const llmResponse = await fetch(
      `${LLM_SERVICE_URL}/api/v1/search/stream`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          query: userQuery,
          model: model,
          chat_history: chatHistory,
          stream: true,
          max_results: 10,
          max_tokens: 4000,
          temperature: 0.7,
        }),
        // æœç´¢å¯èƒ½æ›´æ…¢ï¼Œè®¾ç½® 90 ç§’è¶…æ—¶
        signal: AbortSignal.timeout(90000),
      }
    );

    if (!llmResponse.ok) {
      const errorText = await llmResponse.text();
      console.error('âŒ LLM Service æœç´¢é”™è¯¯:', errorText);

      return new Response(
        JSON.stringify({
          error: 'LLM Service æœç´¢é”™è¯¯',
          details: errorText,
        }),
        {
          status: llmResponse.status,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }

    log.debug('âœ… LLM Service æœç´¢å“åº”æˆåŠŸ');

    // ========================================================================
    // 3. è¿”å›æµå¼å“åº”ï¼ˆæ”¯æŒæœç´¢ç»“æœï¼‰
    // ========================================================================
    return createStreamResponse(llmResponse, true); // true è¡¨ç¤ºæœç´¢æ¨¡å¼
    
  } catch (error) {
    console.error('âŒ Web search error:', error);
    return new Response(
      JSON.stringify({ error: error.message || 'Search failed' }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
}

// ============================================================================
// ğŸ†• æ–°å¢å‡½æ•°ï¼šåˆ›å»ºæµå¼å“åº”ï¼ˆç»Ÿä¸€å¤„ç†ï¼‰
// ============================================================================
/**
 * åˆ›å»ºæµå¼å“åº”ï¼ˆç»Ÿä¸€å¤„ç†æ™®é€šå¯¹è¯å’Œæœç´¢ï¼‰
 * 
 * @param {Response} llmResponse - LLM Service çš„å“åº”
 * @param {boolean} isSearch - æ˜¯å¦ä¸ºæœç´¢æ¨¡å¼
 */
function createStreamResponse(llmResponse, isSearch = false) {
  const encoder = new TextEncoder();
  const decoder = new TextDecoder();

  const readable = new ReadableStream({
    async start(controller) {
      let isClosed = false;

      // ----------------------------------------------------------------
      // è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨å†™å…¥æ•°æ®
      // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
      // ----------------------------------------------------------------
      const safeEnqueue = (data) => {
        if (isClosed) return false;
        try {
          controller.enqueue(data);
          return true;
        } catch (error) {
          if (error.code === 'ERR_INVALID_STATE') {
            isClosed = true;
            log.debug('Stream closed during enqueue');
            return false;
          }
          throw error;
        }
      };

      // ----------------------------------------------------------------
      // è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨å…³é—­æµ
      // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
      // ----------------------------------------------------------------
      const safeClose = () => {
        if (isClosed) return;
        try {
          controller.close();
          isClosed = true;
          log.debug('âœ… Stream closed successfully');
        } catch (error) {
          if (error.code === 'ERR_INVALID_STATE') {
            isClosed = true;
            log.debug('Stream already closed');
          } else {
            console.error('Error closing stream:', error);
          }
        }
      };

      try {
        // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
        const reader = llmResponse.body.getReader();
        let buffer = '';

        while (true) {
          const { done, value } = await reader.read();

          if (done) {
            log.debug('ğŸ“­ LLM Service æµç»“æŸ');
            break;
          }

          const chunk = decoder.decode(value, { stream: true });
          buffer += chunk;

          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            if (isClosed) {
              log.debug('Stream closed, stopping iteration');
              break;
            }

            if (!line.trim() || line.startsWith(':')) {
              continue;
            }

            if (line.startsWith('data: ')) {
              const data = line.slice(6);

              if (data === '[DONE]') {
                log.debug('ğŸ“­ æ”¶åˆ° [DONE] æ ‡è®°');
                break;
              }

              try {
                const json = JSON.parse(data);

                // ğŸ†• ä¿®æ”¹ï¼šå¤„ç†ä¸åŒç±»å‹çš„äº‹ä»¶
                if (json.type === 'content' || json.content) {
                  // å†…å®¹å—ï¼ˆå…¼å®¹ä¸¤ç§æ ¼å¼ï¼‰
                  const content = json.type === 'content' ? json.content : json.content;
                  const success = safeEnqueue(
                    encoder.encode(
                      `data: ${JSON.stringify({ content })}\n\n`
                    )
                  );

                  if (!success) {
                    log.debug('Client disconnected, stopping stream');
                    break;
                  }
                } 
                // ğŸ†• æ–°å¢ï¼šå¤„ç†æœç´¢ç»“æœ
                else if (json.type === 'search_results' && isSearch) {
                  log.debug('ğŸ“Š æ”¶åˆ°æœç´¢ç»“æœ:', json.results?.length || 0);
                  safeEnqueue(
                    encoder.encode(
                      `data: ${JSON.stringify({ 
                        type: 'search_results', 
                        results: json.results 
                      })}\n\n`
                    )
                  );
                } 
                // ğŸ†• æ–°å¢ï¼šå¤„ç†çŠ¶æ€æ¶ˆæ¯
                else if (json.type === 'status' && isSearch) {
                  log.debug('â„¹ï¸ çŠ¶æ€:', json.message);
                  safeEnqueue(
                    encoder.encode(
                      `data: ${JSON.stringify({ 
                        type: 'status', 
                        message: json.message 
                      })}\n\n`
                    )
                  );
                } 
                // âœ… ä¿æŒä¸å˜ï¼šå¤„ç†é”™è¯¯
                else if (json.error || json.type === 'error') {
                  console.error('LLM Service é”™è¯¯:', json.error || json.message);
                  safeEnqueue(
                    encoder.encode(
                      `data: ${JSON.stringify({ 
                        error: json.error || json.message 
                      })}\n\n`
                    )
                  );
                  break;
                }
              } catch (parseError) {
                log.debug('æ— æ³•è§£æçš„æ•°æ®:', data);
              }
            }
          }

          if (isClosed) break;
        }

        safeClose();
      } catch (error) {
        console.error('âŒ æµå¼å¤„ç†é”™è¯¯:', error);
        safeEnqueue(
          encoder.encode(
            `data: ${JSON.stringify({ error: 'Stream error' })}\n\n`
          )
        );
        safeClose();
      }
    },

    // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
    cancel(reason) {
      log.debug('Stream cancelled by client:', reason);
    },
  });

  // âœ… ä¿æŒä¸å˜ï¼ˆä»åŸä»£ç å¤åˆ¶ï¼‰
  return new Response(readable, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
    },
  });
}
