"""
============================================================================
è”ç½‘æœç´¢æ¥å£
æ”¯æŒåšæŸ¥ AI æœç´¢ + LLM ç”Ÿæˆ
============================================================================

æ–‡ä»¶ä½ç½®ï¼š
  llm-service/app/api/v1/search.py

æ–‡ä»¶ä½œç”¨ï¼š
  æä¾›è”ç½‘æœç´¢åŠŸèƒ½ï¼Œç»“åˆåšæŸ¥ AI æœç´¢å’Œ LLM ç”Ÿæˆèƒ½åŠ›

ä¸»è¦åŠŸèƒ½ï¼š
  1. è”ç½‘æœç´¢ï¼ˆéæµå¼ï¼‰- ä¸€æ¬¡æ€§è¿”å›æœç´¢ç»“æœå’Œç”Ÿæˆç­”æ¡ˆ
  2. è”ç½‘æœç´¢ï¼ˆæµå¼ï¼‰- å®æ—¶è¿”å›æœç´¢è¿‡ç¨‹å’Œç”Ÿæˆå†…å®¹
  3. æœç´¢ç»“æœå¢å¼º - å°†æœç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™ LLM

å·¥ä½œæµç¨‹ï¼š
  ç”¨æˆ·æé—® â†’ åšæŸ¥ AI æœç´¢ â†’ æå–æœç´¢ç»“æœ â†’ æ„å»ºå¢å¼º Prompt 
  â†’ LLM ç”Ÿæˆç­”æ¡ˆ â†’ è¿”å›ç­”æ¡ˆ + æ¥æºå¼•ç”¨

æŠ€æœ¯æ ˆï¼š
  - FastAPIï¼ˆWeb æ¡†æ¶ï¼‰
  - åšæŸ¥ AIï¼ˆæœç´¢å¼•æ“ï¼‰
  - OpenRouterï¼ˆLLM æä¾›å•†ï¼‰
  - Server-Sent Eventsï¼ˆæµå¼ä¼ è¾“ï¼‰

è·¯ç”±ï¼š
  - POST /search        éæµå¼æœç´¢
  - POST /search/stream æµå¼æœç´¢

ä¾èµ–æœåŠ¡ï¼š
  - åšæŸ¥ AI APIï¼ˆæœç´¢æœåŠ¡ï¼‰
  - OpenRouter APIï¼ˆLLM æœåŠ¡ï¼‰

ä¾èµ–æ–‡ä»¶ï¼š
  - app/core/config.py              é…ç½®ç®¡ç†
  - app/services/bocha_client.py    åšæŸ¥ AI å®¢æˆ·ç«¯

============================================================================
"""
from fastapi import APIRouter, HTTPException  # FastAPI è·¯ç”±å’Œå¼‚å¸¸å¤„ç†
from fastapi.responses import StreamingResponse  # æµå¼å“åº”ç±»
from pydantic import BaseModel, Field  # æ•°æ®éªŒè¯æ¨¡å‹
from typing import List, Dict, Optional, Any  # ç±»å‹æ³¨è§£
from datetime import datetime  # æ—¥æœŸæ—¶é—´å¤„ç†
import json  # JSON åºåˆ—åŒ–
import time  # æ—¶é—´è®¡ç®—
from loguru import logger  # æ—¥å¿—è®°å½•å™¨

from app.core.config import settings  # åº”ç”¨é…ç½®
from app.services.bocha_client import bocha_client  # åšæŸ¥ AI å®¢æˆ·ç«¯
from openai import AsyncOpenAI  # OpenAI å¼‚æ­¥å®¢æˆ·ç«¯ï¼ˆå…¼å®¹ OpenRouterï¼‰

# ============================================================================
# è·¯ç”±å™¨åˆå§‹åŒ–
# ============================================================================
router = APIRouter()  # åˆ›å»º FastAPI è·¯ç”±å™¨å®ä¾‹

# ============================================================================
# OpenRouter å®¢æˆ·ç«¯åˆå§‹åŒ–
# ============================================================================
# åˆå§‹åŒ– OpenRouter å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ OpenAI SDK å…¼å®¹æ¥å£ï¼‰
openai_client = AsyncOpenAI(
    api_key=settings.OPENROUTER_API_KEY,  # ä»é…ç½®è¯»å– API Key
    base_url=settings.OPENROUTER_BASE_URL or "https://openrouter.ai/api/v1"  # OpenRouter API åœ°å€
)


# ============================================================================
# Pydantic æ¨¡å‹å®šä¹‰
# ============================================================================

class Message(BaseModel):
    """
    æ¶ˆæ¯æ¨¡å‹
    
    ç”¨äºè¡¨ç¤ºèŠå¤©å†å²ä¸­çš„å•æ¡æ¶ˆæ¯
    """
    role: str = Field(..., description="è§’è‰²ï¼šsystem/user/assistant")  # æ¶ˆæ¯è§’è‰²
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")  # æ¶ˆæ¯æ–‡æœ¬å†…å®¹


class SearchRequest(BaseModel):
    """
    æœç´¢è¯·æ±‚æ¨¡å‹
    
    å®šä¹‰æœç´¢æ¥å£çš„è¯·æ±‚å‚æ•°ç»“æ„å’ŒéªŒè¯è§„åˆ™
    """
    query: str = Field(..., min_length=1, max_length=500, description="æœç´¢å…³é”®è¯")  # æœç´¢æŸ¥è¯¢ï¼ˆå¿…å¡«ï¼Œ1-500 å­—ç¬¦ï¼‰
    model: str = Field(settings.OPENROUTER_DEFAULT_MODEL, description="ä½¿ç”¨çš„æ¨¡å‹")  # LLM æ¨¡å‹åç§°ï¼ˆé»˜è®¤å€¼ä»é…ç½®è¯»å–ï¼‰
    chat_history: Optional[List[Message]] = Field([], description="èŠå¤©å†å²")  # å†å²å¯¹è¯ï¼ˆå¯é€‰ï¼Œç”¨äºå¤šè½®å¯¹è¯ï¼‰
    stream: bool = Field(False, description="æ˜¯å¦æµå¼å“åº”")  # æ˜¯å¦å¯ç”¨æµå¼ä¼ è¾“
    max_results: int = Field(10, ge=1, le=20, description="æœ€å¤§æœç´¢ç»“æœæ•°")  # æœç´¢ç»“æœæ•°é‡ï¼ˆ1-20ï¼‰
    max_tokens: int = Field(2000, ge=1, le=4096, description="æœ€å¤§ç”Ÿæˆé•¿åº¦")  # LLM ç”Ÿæˆçš„æœ€å¤§ token æ•°
    temperature: float = Field(0.7, ge=0, le=2, description="æ¸©åº¦")  # æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰

    class Config:
        # Swagger æ–‡æ¡£ç¤ºä¾‹
        json_schema_extra = {
            "example": {
                "query": "2024å¹´AIæœ€æ–°è¿›å±•",
                "model": "openai/gpt-4o",
                "stream": False,
                "max_results": 10
            }
        }


class SearchSource(BaseModel):
    """
    æœç´¢æ¥æºæ¨¡å‹
    
    è¡¨ç¤ºå•ä¸ªæœç´¢ç»“æœçš„å…ƒæ•°æ®
    """
    title: str  # ç½‘é¡µæ ‡é¢˜
    url: str  # ç½‘é¡µ URL
    content: str  # ç½‘é¡µå†…å®¹æ‘˜è¦
    publishedDate: Optional[str] = None  # å‘å¸ƒæ—¥æœŸï¼ˆå¯é€‰ï¼‰
    siteName: Optional[str] = None  # ç½‘ç«™åç§°ï¼ˆå¯é€‰ï¼‰


class SearchResponse(BaseModel):
    """
    æœç´¢å“åº”æ¨¡å‹
    
    å®šä¹‰æœç´¢æ¥å£çš„è¿”å›æ•°æ®ç»“æ„
    """
    answer: str = Field(..., description="ç”Ÿæˆçš„å›ç­”")  # LLM ç”Ÿæˆçš„ç­”æ¡ˆ
    sources: List[SearchSource] = Field(..., description="æœç´¢æ¥æº")  # æœç´¢ç»“æœæ¥æºåˆ—è¡¨
    search_results: List[Dict[str, Any]] = Field(..., description="åŸå§‹æœç´¢ç»“æœ")  # å®Œæ•´çš„åŸå§‹æœç´¢æ•°æ®
    model: str = Field(..., description="ä½¿ç”¨çš„æ¨¡å‹")  # ä½¿ç”¨çš„ LLM æ¨¡å‹åç§°
    tokens_used: int = Field(..., description="æ¶ˆè€—çš„ Token æ•°")  # LLM æ¶ˆè€—çš„ token æ•°é‡
    latency_ms: int = Field(..., description="å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰")  # æ€»è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰


# ============================================================================
# API ç«¯ç‚¹ 1ï¼šè”ç½‘æœç´¢ï¼ˆéæµå¼ï¼‰
# ============================================================================

@router.post("/search", response_model=SearchResponse)  # è·¯ç”±ï¼šPOST /api/v1/search
async def web_search(request: SearchRequest):
    """
    è”ç½‘æœç´¢ + LLM ç”Ÿæˆï¼ˆéæµå¼ï¼‰

    å·¥ä½œæµç¨‹ï¼š
    1. è°ƒç”¨åšæŸ¥ API æœç´¢
    2. æå–æœç´¢ç»“æœ
    3. æ„å»ºå¢å¼º Prompt
    4. è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆ
    5. è¿”å›ç­”æ¡ˆ + æ¥æº
    
    åŠŸèƒ½è¯´æ˜ï¼š
      - æ ¹æ®ç”¨æˆ·é—®é¢˜æœç´¢äº’è”ç½‘å†…å®¹
      - å°†æœç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™ LLM
      - LLM åŸºäºæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ
      - è¿”å›ç­”æ¡ˆå’Œå¼•ç”¨æ¥æº
    
    å‚æ•°ï¼š
      request (SearchRequest): åŒ…å«ä»¥ä¸‹å­—æ®µ
        - query: æœç´¢å…³é”®è¯
        - model: LLM æ¨¡å‹åç§°
        - chat_history: èŠå¤©å†å²ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ï¼‰
        - max_results: æœ€å¤§æœç´¢ç»“æœæ•°
        - max_tokens: æœ€å¤§ç”Ÿæˆé•¿åº¦
        - temperature: æ¸©åº¦å‚æ•°
    
    è¿”å›ï¼š
      SearchResponse: åŒ…å«ä»¥ä¸‹å­—æ®µ
        - answer: LLM ç”Ÿæˆçš„ç­”æ¡ˆ
        - sources: æœç´¢æ¥æºåˆ—è¡¨
        - search_results: åŸå§‹æœç´¢ç»“æœ
        - model: ä½¿ç”¨çš„æ¨¡å‹
        - tokens_used: æ¶ˆè€—çš„ token æ•°
        - latency_ms: æ€»è€—æ—¶
    
    å¼‚å¸¸ï¼š
      HTTPException 404: æœªæ‰¾åˆ°æœç´¢ç»“æœ
      HTTPException 500: æœç´¢å¤±è´¥
    """
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—å»¶è¿Ÿï¼‰

    try:
        # ========== 1. æ‰§è¡Œæœç´¢ ==========
        logger.info(f"ğŸ” å¼€å§‹æœç´¢: {request.query}")

        # è°ƒç”¨åšæŸ¥ AI æœç´¢æœåŠ¡
        search_result = await bocha_client.search(
            query=request.query,  # æœç´¢å…³é”®è¯
            count=request.max_results  # è¿”å›ç»“æœæ•°é‡
        )

        # æå–æœç´¢ç»“æœåˆ—è¡¨
        results = search_result.get("results", [])

        # å¦‚æœæ²¡æœ‰æœç´¢ç»“æœï¼Œè¿”å› 404 é”™è¯¯
        if not results:
            raise HTTPException(
                status_code=404,
                detail="æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"
            )

        # ========== 2. æ„å»ºå¢å¼º Prompt ==========
        # å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        context = _build_search_context(results)

        # æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆåŒ…å«æœç´¢ç»“æœå’Œå›ç­”è¦æ±‚ï¼‰
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨æœç´¢ç»“æœæ¥å›ç­”é—®é¢˜ã€‚
                        ## å½“å‰æ—¶é—´
                        {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

                        ## æœç´¢ç»“æœ
                        {context}

                        ## å›ç­”è¦æ±‚
                        1. åŸºäºæœç´¢ç»“æœå›ç­”é—®é¢˜
                        2. å¼•ç”¨æ¥æºæ—¶æ ‡æ³¨åºå·ï¼ˆå¦‚ [1]ã€[2]ï¼‰
                        3. ä½¿ç”¨ Markdown æ ¼å¼
                        4. ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹åˆ—å‡º
                        5. å¦‚æœæœç´¢ç»“æœä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œæ˜ç¡®è¯´æ˜"""

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆç”¨äº LLM è°ƒç”¨ï¼‰
        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ èŠå¤©å†å²ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ï¼‰
        if request.chat_history:
            for msg in request.chat_history:
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })

        # æ·»åŠ ç”¨æˆ·é—®é¢˜
        messages.append({
            "role": "user",
            "content": request.query
        })

        # ========== 3. è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆ ==========
        logger.info(f" è°ƒç”¨ LLM: {request.model}")

        # è°ƒç”¨ OpenRouter API ç”Ÿæˆç­”æ¡ˆ
        response = await openai_client.chat.completions.create(
            model=request.model,  # æŒ‡å®šæ¨¡å‹
            messages=messages,  # æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºã€å†å²ã€ç”¨æˆ·é—®é¢˜ï¼‰
            max_tokens=request.max_tokens,  # æœ€å¤§ç”Ÿæˆé•¿åº¦
            temperature=request.temperature  # æ¸©åº¦å‚æ•°
        )

        # æå–ç”Ÿæˆçš„ç­”æ¡ˆå’Œ token ä½¿ç”¨é‡
        answer = response.choices[0].message.content
        tokens_used = response.usage.total_tokens

        # ========== 4. æ„å»ºå“åº” ==========
        # è®¡ç®—æ€»è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
        latency_ms = int((time.time() - start_time) * 1000)

        # æ„å»ºæ¥æºåˆ—è¡¨ï¼ˆæå–å…³é”®ä¿¡æ¯ï¼‰
        sources = [
            SearchSource(
                title=r["title"],
                url=r["url"],
                content=r["content"][:200] + "..." if len(r["content"]) > 200 else r["content"],  # æˆªæ–­é•¿å†…å®¹
                publishedDate=r.get("publishedDate"),
                siteName=r.get("siteName")
            )
            for r in results
        ]

        logger.info(f" æœç´¢å®Œæˆï¼Œè€—æ—¶ {latency_ms}ms")

        # è¿”å›æ ‡å‡†å“åº”
        return SearchResponse(
            answer=answer,  # LLM ç”Ÿæˆçš„ç­”æ¡ˆ
            sources=sources,  # æœç´¢æ¥æºåˆ—è¡¨
            search_results=results,  # åŸå§‹æœç´¢ç»“æœ
            model=request.model,  # ä½¿ç”¨çš„æ¨¡å‹
            tokens_used=tokens_used,  # æ¶ˆè€—çš„ token æ•°
            latency_ms=latency_ms  # æ€»è€—æ—¶
        )

    except HTTPException:
        raise  # é‡æ–°æŠ›å‡º HTTP å¼‚å¸¸
    except Exception as e:
        logger.error(f" æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


# ============================================================================
# API ç«¯ç‚¹ 2ï¼šè”ç½‘æœç´¢ï¼ˆæµå¼ï¼‰
# ============================================================================

@router.post("/search/stream")  # è·¯ç”±ï¼šPOST /api/v1/search/stream
async def web_search_stream(request: SearchRequest):
    """
    è”ç½‘æœç´¢ + LLM ç”Ÿæˆï¼ˆæµå¼ï¼‰

    è¿”å› Server-Sent Events æ ¼å¼
    
    åŠŸèƒ½è¯´æ˜ï¼š
      - å®æ—¶è¿”å›æœç´¢è¿›åº¦å’Œç”Ÿæˆå†…å®¹
      - é€‚ç”¨äºéœ€è¦å®æ—¶åé¦ˆçš„åœºæ™¯
    
    äº‹ä»¶ç±»å‹ï¼š
      - status: çŠ¶æ€æ›´æ–°ï¼ˆå¦‚ "æ­£åœ¨æœç´¢..."ï¼‰
      - search_results: æœç´¢ç»“æœ
      - content: LLM ç”Ÿæˆçš„å†…å®¹ç‰‡æ®µ
      - error: é”™è¯¯ä¿¡æ¯
      - [DONE]: å®Œæˆæ ‡è®°
    
    å“åº”æ ¼å¼ï¼š
      data: {"type": "status", "message": "æ­£åœ¨æœç´¢..."}\n\n
      data: {"type": "search_results", "results": [...], "total": 10}\n\n
      data: {"type": "content", "content": "æ–‡æœ¬ç‰‡æ®µ"}\n\n
      data: [DONE]\n\n
    """

    async def generate():
        """
        å¼‚æ­¥ç”Ÿæˆå™¨å‡½æ•°
        
        é€æ­¥è¿”å›æœç´¢å’Œç”Ÿæˆçš„å†…å®¹
        """
        try:
            # ========== 1. æ‰§è¡Œæœç´¢ ==========
            logger.info(f"ğŸ” å¼€å§‹æœç´¢: {request.query}")

            # å‘é€æœç´¢çŠ¶æ€ï¼ˆå‘ŠçŸ¥å‰ç«¯æ­£åœ¨æœç´¢ï¼‰
            yield f"data: {json.dumps({'type': 'status', 'message': 'æ­£åœ¨æœç´¢...'}, ensure_ascii=False)}\n\n"

            # è°ƒç”¨åšæŸ¥ AI æœç´¢
            search_result = await bocha_client.search(
                query=request.query,
                count=request.max_results
            )

            results = search_result.get("results", [])

            # å¦‚æœæ²¡æœ‰æœç´¢ç»“æœï¼Œè¿”å›é”™è¯¯
            if not results:
                yield f"data: {json.dumps({'type': 'error', 'message': 'æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ'}, ensure_ascii=False)}\n\n"
                yield "data: [DONE]\n\n"  # å‘é€å®Œæˆæ ‡è®°
                return

            # å‘é€æœç´¢ç»“æœï¼ˆè®©å‰ç«¯æ˜¾ç¤ºæ¥æºï¼‰
            yield f"data: {json.dumps({'type': 'search_results', 'results': results, 'total': len(results)}, ensure_ascii=False)}\n\n"

            # ========== 2. æ„å»ºå¢å¼º Prompt ==========
            context = _build_search_context(results)

            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨æœç´¢ç»“æœæ¥å›ç­”é—®é¢˜ã€‚
                            ## å½“å‰æ—¶é—´
                            {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

                            ## æœç´¢ç»“æœ
                            {context}

                            ## å›ç­”è¦æ±‚
                            1. åŸºäºæœç´¢ç»“æœå›ç­”é—®é¢˜
                            2. å¼•ç”¨æ¥æºæ—¶æ ‡æ³¨åºå·ï¼ˆå¦‚ [1]ã€[2]ï¼‰
                            3. ä½¿ç”¨ Markdown æ ¼å¼
                            4. ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹åˆ—å‡º
                            5. å¦‚æœæœç´¢ç»“æœä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œæ˜ç¡®è¯´æ˜"""

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]

            # æ·»åŠ èŠå¤©å†å²
            if request.chat_history:
                for msg in request.chat_history:
                    messages.append({"role": msg.role, "content": msg.content})

            # æ·»åŠ ç”¨æˆ·é—®é¢˜
            messages.append({"role": "user", "content": request.query})

            # ========== 3. æµå¼è°ƒç”¨ LLM ==========
            logger.info(f" è°ƒç”¨ LLM: {request.model}")

            # å‘é€ç”ŸæˆçŠ¶æ€
            yield f"data: {json.dumps({'type': 'status', 'message': 'æ­£åœ¨ç”Ÿæˆå›ç­”...'}, ensure_ascii=False)}\n\n"

            # è°ƒç”¨ OpenRouter APIï¼ˆæµå¼æ¨¡å¼ï¼‰
            stream = await openai_client.chat.completions.create(
                model=request.model,
                messages=messages,
                max_tokens=request.max_tokens,
                temperature=request.temperature,
                stream=True  # å¯ç”¨æµå¼ä¼ è¾“
            )

            # ========== 4. æµå¼è¾“å‡º ==========
            # é€å—è¿”å› LLM ç”Ÿæˆçš„å†…å®¹
            async for chunk in stream:
                # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹ï¼ˆchunk å¯èƒ½åªåŒ…å«å…ƒæ•°æ®ï¼‰
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    # å‘é€å†…å®¹ç‰‡æ®µ
                    yield f"data: {json.dumps({'type': 'content', 'content': content}, ensure_ascii=False)}\n\n"

            # å‘é€å®Œæˆæ ‡è®°
            yield "data: [DONE]\n\n"

            logger.info(" æµå¼æœç´¢å®Œæˆ")

        except Exception as e:
            # å¼‚å¸¸å¤„ç†ï¼šå‘é€é”™è¯¯ä¿¡æ¯
            logger.error(f" æµå¼æœç´¢å¤±è´¥: {e}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"

    # è¿”å›æµå¼å“åº”
    return StreamingResponse(generate(), media_type="text/event-stream")


# ============================================================================
# å†…éƒ¨å‡½æ•°
# ============================================================================

def _build_search_context(results: List[Dict[str, Any]]) -> str:
    """
    æ„å»ºæœç´¢ä¸Šä¸‹æ–‡
    
    åŠŸèƒ½è¯´æ˜ï¼š
      - å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºç»“æ„åŒ–æ–‡æœ¬
      - ä½œä¸º LLM çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
      - åŒ…å«æ ‡é¢˜ã€æ¥æºã€å†…å®¹ç­‰å…³é”®ä¿¡æ¯

    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨ï¼ˆæ¥è‡ªåšæŸ¥ AIï¼‰

    Returns:
        æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        
    æ ¼å¼ç¤ºä¾‹ï¼š
        [1] æ–‡ç« æ ‡é¢˜
        æ¥æº: https://example.com
        ç½‘ç«™: Example Site
        å‘å¸ƒæ—¶é—´: 2024-01-01
        å†…å®¹: æ–‡ç« å†…å®¹æ‘˜è¦...
    """
    context_parts = []  # å­˜å‚¨æ¯ä¸ªæœç´¢ç»“æœçš„æ ¼å¼åŒ–æ–‡æœ¬

    # éå†æœç´¢ç»“æœï¼Œæ·»åŠ åºå·ï¼ˆä» 1 å¼€å§‹ï¼‰
    for i, result in enumerate(results, start=1):
        # æ ¼å¼åŒ–å•ä¸ªæœç´¢ç»“æœ
        context_parts.append(f"""[{i}] {result['title']}
æ¥æº: {result['url']}
ç½‘ç«™: {result.get('siteName', 'æœªçŸ¥')}
å‘å¸ƒæ—¶é—´: {result.get('publishedDate', 'æœªçŸ¥')}
å†…å®¹: {result['content']}
""")

    # ç”¨æ¢è¡Œç¬¦è¿æ¥æ‰€æœ‰ç»“æœ
    return "\n".join(context_parts)
